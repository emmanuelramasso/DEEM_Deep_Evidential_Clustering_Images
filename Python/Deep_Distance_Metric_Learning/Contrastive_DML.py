import torch
import random
from torch.utils.data import Dataset
from tqdm.auto import tqdm
import matplotlib.pyplot as plt
import torch
import os 
from PIL import Image
from scipy.optimize import linear_sum_assignment
import numpy as np

#################################################
# Custom Dataset to generate triplets
class UnsupervisedTripletDataset(Dataset):
    def __init__(self, dataset, transform, transformAnchor):
        self.dataset = dataset
        self.transform = transform        
        self.transformAnchor = transformAnchor # the positive is generated by another transform that adds randomness
        
    def __getitem__(self, index):        
        anchor, anchor_label = self.dataset[index] # Anchor sample: randomly chosen image, use anchor_label for eval ONLY
        # easy to generate a positive...        
        positive, positive_label = anchor, anchor_label # Positive sample: different augmentation of the SAME image 
        anchor = self.transformAnchor(anchor)
        positive = self.transform(positive)
                
        negative_index = index # Negative sample: different image randomly chosen from the dataset
        while negative_index == index:
            negative_index = random.randint(0, len(self.dataset) - 1)
        negative, negative_label = self.dataset[negative_index]  # use negative_label for eval ONLY
        negative = self.transform(negative)          
        
        # we must return sth like supervised
        indicesAPN = torch.tensor([[-1,-1],[-1,-1],[-1,-1]])
        bools_APN = torch.tensor([[True],[False],[False]])  # one similar
        #print(indicesAPN)
        #print(bools_APN)
        
        return anchor, positive, negative, anchor_label, positive_label, negative_label, indicesAPN, bools_APN

    def __len__(self):
        return len(self.dataset)
    
    
class SupervisedTripletDataset(Dataset):
    """Draws samples in labeled indices, get a positive of same label and a negative of different label

    Args:
        dataset (Dataset): Contains a training dataset
        transformAnchor (transform): Transformation to be applied on anchor, pos and neg images
        labeled_indices: indices corresponding to labeled data in the training set
        
    Returns:
        anchor, positive, negative, anchor_label, positive_label, negative_label
        
    """
    def __init__(self, dataset, transformAnchor, labeled_indices):
        self.dataset = dataset
        self.transformAnchor = transformAnchor  # Transform for the anchor, P, N images
        self.labeled_indices = set(labeled_indices)
        
        # Precompute positive and negative index lists for each label
        self.label_to_indices = self._precompute_label_indices()            
        
    def _precompute_label_indices(self):
        label_to_indices = {}
        
        for idx in self.labeled_indices:
            _, label = self.dataset[idx]
            if label not in label_to_indices:
                label_to_indices[label] = []
            label_to_indices[label].append(idx) # indices avec le meme label
        
        return label_to_indices

    def __getitem__(self, index):
        # draws the positive samples from the precomputed list of labeled indices (self.label_to_indices) for each label. 
        # The variable positives = self.label_to_indices.get(anchor_label, []) retrieves the list of indices corresponding to the label of the anchor (anchor_label).
        # Then, it randomly selects a positive sample index from this list using random.choice(positives). 
        # The positive sample is always drawn from the same label as the anchor, as stored in the label_to_indices dictionary.
    
        anchor, anchor_label = self.dataset[index]  # Anchor sample
        anchor = self.transformAnchor(anchor)
        
        # Get precomputed positives and negatives for the anchor's label
        positives = self.label_to_indices.get(anchor_label, [])
        negatives = [idx for lbl, indices in self.label_to_indices.items() if lbl != anchor_label for idx in indices]
        
        if not positives or not negatives:
            raise ValueError(f"Could not find positive/negative samples for anchor at index {index}")
        
        # Sample a positive and negative
        # Ensure 'index' is excluded from 'positives' before selecting a positive_index
        valid_positives = [pos for pos in positives if pos != index]
        # If there are any valid positives, select one; otherwise, handle the case
        if valid_positives:
            positive_index = random.choice(valid_positives)
        else:
            # Handle the case where no valid positives are left
            raise ValueError(f"No valid positive indices available for index {index}")
        
        negative_index = random.choice(negatives)
        assert(positive_index!=negative_index and positive_index!=index and negative_index!=index)
        
        # Fetch positive and negative samples
        positive, positive_label = self.dataset[positive_index]
        negative, negative_label = self.dataset[negative_index]
        
        # Apply the anchor transformation
        positive = self.transformAnchor(positive)
        negative = self.transformAnchor(negative)
        
        # We can get three pairs of sim/dissimilar objects
        # We create a tensor of indices and corresponding bools (A,P), (A,N), (P,N)
        # This creates 3 pairs: (Anchor, Positive), (Anchor, Negative), and (Positive, Negative).
        # The first pair (Anchor, Positive) is must-link.
        # The other two pairs are cannot-link.
        # indicesAPN: (N, 3, 2) -> 3 pairs per sample.
        # bools_APN: (N, 3, 1) ->  Corresponding boolean constraints.
        indicesAPN = torch.tensor([[index,positive_index],[index,negative_index],[positive_index,negative_index]])
        bools_APN = torch.tensor([[True],[False],[False]]) # one similar
        
        return anchor, positive, negative, anchor_label, positive_label, negative_label, indicesAPN, bools_APN

    def __len__(self):
        return len(self.dataset)

# combine supervised and unsupervised case
class CombinedSemiSupervisedTripletDataset(Dataset):
    def __init__(self, dataset, transform, transformAnchor, labeled_indices, supervised_prob, pathlabeledidxfile):
        self.dataset = dataset
        self.supervised_prob = supervised_prob
        self.labeled_indices = set(labeled_indices)  # Convert list to set for quick lookup
        self.unsupervised_dataset = UnsupervisedTripletDataset(dataset, transform, transformAnchor)
        self.supervised_dataset = SupervisedTripletDataset(dataset, transformAnchor, labeled_indices)
                
        # Vérifie coherence noms de fichiers considérés labelisés ici et evnn
        self._save_labeled_file_paths(labeled_indices, pathlabeledidxfile)

    def _save_labeled_file_paths(self, labeled_indices, pathlabeledidxfile):
        """Sauvegarde les chemins des fichiers correspondant aux données labelisées"""
        if len(labeled_indices) == 0:  # Correct check for empty NumPy array
            print(f"No labeled data, skipping file write.")
            return
    
        #labeled_file_paths = [self.dataset.image_paths[i] for i in labeled_indices]
        labeled_file_paths = [os.path.abspath(self.dataset.image_paths[i]) for i in labeled_indices]
        with open(pathlabeledidxfile, 'w') as f:
            for path in labeled_file_paths:
                #print(path)
                f.write(f"{path}\n")                
        
    def __getitem__(self, index):
        # Directly use labeled_indices to determine if supervised or unsupervised
        if index in self.labeled_indices:
            return self.supervised_dataset[index]
        else:
            return self.unsupervised_dataset[index]
    
    def __len__(self):
        return len(self.unsupervised_dataset)


#################################################

import torch.nn as nn
import torch.nn.functional as F

""" class SimpleCNN(nn.Module):
    def __init__(self, in_channels=1):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)
        self.fc1 = nn.Linear(128 * 7 * 7, 256) # self.fc1 = nn.Linear(128 * 8 * 8, 256) for 3 channels
        self.fc2 = nn.Linear(256, 128)
        #self.fc2 = nn.Linear(256, 32)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2)
        x = x.view(x.size(0), -1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x """
        
class SimpleCNN(nn.Module):
    def __init__(self, in_channels=1):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(2, 2)  # Define the pooling layer as an attribute
        self.fc1 = nn.Linear(128 * 7 * 7, 256)
        self.fc2 = nn.Linear(256, 128)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool(x)  # Use the pool attribute instead of F.max_pool2d
        x = F.relu(self.conv2(x))
        x = self.pool(x)  # Use the pool attribute instead of F.max_pool2d
        x = x.view(x.size(0), -1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

class CustomDeeperCNN1_224x224(nn.Module):
    def __init__(self, in_channels=3):
        super(CustomDeeperCNN1_224x224, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)
        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)
        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(512 * 14 * 14, 1024)
        self.fc2 = nn.Linear(1024, 128)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool(x)
        x = F.relu(self.conv2(x))
        x = self.pool(x)
        x = F.relu(self.conv3(x))
        x = self.pool(x)
        x = F.relu(self.conv4(x))
        x = self.pool(x)
        x = x.view(x.size(0), -1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

    
# this method uses euclidean distance to evaluate similarity
def evaluate_model_meth0dist(model, combined_dataset, dataloader, device, num_samples=10000):
    
    model.eval()
    
    total_correct = 0
    total_samples = 0
    pdist = nn.PairwiseDistance(p=2)
    # set the prob = 1 to force supervised mode in eval
    # in that way we are sure the eval is on negative labels != from positive labels
    # and positive images are different from anchors but from the same labels
    # Temporarily set supervised_prob to 1 for evaluation
    original_supervised_prob = combined_dataset.supervised_prob
    combined_dataset.supervised_prob = 1.0
    
    with torch.no_grad():
        for i, (anchors, positives, negatives, anchor_labels, positive_labels, negative_labels, _, _) in enumerate(dataloader):
            if i * dataloader.batch_size >= num_samples:
                break
            #
            # pour l'eval dans cette version
            # on fait passer A P et N dans le réseau
            # !! on calcule la distance de la meme manière que lors du training
            #
            # si les labels sont différents entre P et N
            # alors la distance entre P et N doit etre > à la distance entre A et P
            # où P et une version bruitée de A
            # mettre a jour le vecteur des dij differentes classes
            # 
            # si les labels sont les memes entre P et N 
            # mettre a jour le vecteur des dij classes egales
 
            anchors     = anchors.float().to(device=device)
            positives   = positives.float().to(device=device)
            negatives   = negatives.float().to(device=device)

            anchor_emb   = model(anchors)
            positive_emb = model(positives)
            negative_emb = model(negatives)

            # use same distance as triplet loss            
            #pos_distances = torch.norm(anchor_emb - positive_emb, dim=1)
            #neg_distances = torch.norm(anchor_emb - negative_emb, dim=1)
            pos_distances = pdist(anchor_emb, positive_emb)
            neg_distances = pdist(anchor_emb, negative_emb)
            
            # Convert labels to LongTensor for comparison
            anchor_labels   = anchor_labels.long().to(device=device)
            positive_labels = positive_labels.long().to(device=device)
            negative_labels = negative_labels.long().to(device=device)
            
            # SUPPOSE POSITIVE AND ANCHOR HAVE THE SAME LABELS
            # find data with different labels for N and A
            # for those cases we must have pos_distances < neg_distances
            correct = (pos_distances < neg_distances).float()
            mask_different_labels = (negative_labels != anchor_labels)
            correct = correct[mask_different_labels]
            #print(f'avant filtrage {len(negative_labels)} after {len(correct)}')
            
            total_correct += correct.sum().item()
            total_samples += len(correct)

    accuracy = total_correct / total_samples
    print(f'Accuracy: {accuracy * 100:.2f}%')

    # Restore the original supervised_prob
    combined_dataset.supervised_prob = original_supervised_prob    
    model.train()

##########################

def evaluate_model_meth0dist_all_pairs(model, dataloader, device, num_pairs=300000):
    # Here we can sample supervised or unsupervised, we take many couples but the sampling respect the distribution fiexed with supervised_prob
    # The supervision only plays a role for the loss but here we want to get the statistics on the output ie mean and std
    # We take all ANCHOR embeddings and take the mean values and std
    
    model.eval()
    
    total_correct = 0
    total_samples = 0
    pdist = nn.PairwiseDistance(p=2)
    same_label_dists = []
    diff_label_dists = []
    labels_pos = []
    labels_neg = []
    running_mean = None
    running_M2 = None
    sample_count = 0
            
    with torch.no_grad():
        for i, (anchors, positives, negatives, anchor_labels, positive_labels, negative_labels, _,_) in tqdm(enumerate(dataloader), total=len(dataloader)):
            
            if i * dataloader.batch_size >= num_pairs:
                break
            
            # Combine all triplet samples in one batch
            anchors     = anchors.float().to(device=device)
            positives   = positives.float().to(device=device)
            negatives   = negatives.float().to(device=device)

            anchor_embeddings   = model(anchors)
            positive_embeddings = model(positives)
            negative_embeddings = model(negatives)

            # Update running statistics -- We need mean and std on CNN outputs, to standardize in EVNN
            #for idx, embedding in enumerate(anchor_embeddings):
                ##if supervisedOrnot[idx] == True: NOT NECESSARY we take all data
            for embedding in anchor_embeddings:
                sample_count += 1
                if running_mean is None:
                    running_mean = torch.zeros_like(embedding)
                    running_M2 = torch.zeros_like(embedding)
                    
                delta = embedding - running_mean
                running_mean += delta / sample_count
                delta2 = embedding - running_mean
                running_M2 += delta * delta2

            running_variance = running_M2 / (sample_count - 1)
            running_stddev = torch.sqrt(running_variance)
            
            # Iterate over each anchor sample
            for j in range(anchor_embeddings.size(0)):
                pos_distance = pdist(anchor_embeddings[j].unsqueeze(0), positive_embeddings[j].unsqueeze(0)).item()
                # anchor and positive have same label even in unsupervised by construction
                same_label_dists.append(pos_distance)
                labels_pos.append(anchor_labels[j])
                
                # Compare with all negatives in the batch
                for k in range(negative_embeddings.size(0)):
                    neg_distance = pdist(anchor_embeddings[j].unsqueeze(0), negative_embeddings[k].unsqueeze(0)).item()
                    labels_neg.append(negative_labels[k])
                
                    # Only count if negative and anchor have different labels
                    if anchor_labels[j] != negative_labels[k]:
                        total_samples += 1
                        diff_label_dists.append(neg_distance)
                        
                        if pos_distance < neg_distance:
                            total_correct += 1
                            
                    else:
                        same_label_dists.append(pos_distance)                                                       

    accuracy = total_correct / total_samples if total_samples > 0 else 0
    print(f'Accuracy: {accuracy * 100:.2f}% (with N={total_samples} samples)')
    print(f'm={running_mean}')
    print(f's={running_stddev}')
    
    model.train()
    return same_label_dists, diff_label_dists, labels_pos, labels_neg, running_mean.cpu().numpy(), running_stddev.cpu().numpy()


# Function to plot histograms

def plot_histograms(same_label_dists, diff_label_dists, path):
    plt.figure(figsize=(12, 6))

    plt.subplot(1, 2, 1)
    plt.hist(same_label_dists, bins=50, alpha=0.75, color='blue')
    plt.title('Histogram of Distances (Same Labels)')
    plt.xlabel('Distance')
    plt.ylabel('Frequency')

    plt.subplot(1, 2, 2)
    plt.hist(diff_label_dists, bins=50, alpha=0.75, color='red')
    plt.title('Histogram of Distances (Different Labels)')
    plt.xlabel('Distance')
    plt.ylabel('Frequency')

    plt.tight_layout()
    #plt.show()
    
    # Save the figure
    #filename = f'figure_epoch_{epoch:03d}.png' 
    plt.savefig(path) #+'/'+filename)
    plt.close()  # Close the figure to free memory
    
#################################################

# MARGIN ??
def triplet_loss(anchor, positive, negative, margin):
    pdist = nn.PairwiseDistance(p=2)
    positive_distance = pdist(anchor, positive)
    negative_distance = pdist(anchor, negative)
    loss = F.relu(positive_distance - negative_distance + margin)
    return loss.mean()
# VOIR SI IDEM A https://pytorch.org/docs/stable/generated/torch.nn.TripletMarginLoss.html#torch.nn.TripletMarginLoss
#triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2, eps=1e-7)
#anchor = torch.randn(100, 128, requires_grad=True)
#positive = torch.randn(100, 128, requires_grad=True)
#negative = torch.randn(100, 128, requires_grad=True)
#output = triplet_loss(anchor, positive, negative)
#output.backward()


#####

class SortedImageDataset(Dataset):
    def __init__(self, root_dir, transform=None, target_transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.target_transform = target_transform
        self.image_paths = self._get_sorted_image_paths(root_dir)
        self.class_names_to_idx = self._get_class_names_to_idx()
        self.labels = self._get_labels()

    def _get_sorted_image_paths(self, root_dir):
        image_paths = []
        for subdir, _, files in sorted(os.walk(root_dir)):
            # Sort files to ensure deterministic order
            for file in sorted(files):
                if file.lower().endswith(('.jpg', '.png', '.jpeg')):
                    image_paths.append(os.path.join(subdir, file))
        return image_paths

    def _get_class_names_to_idx(self):
        # Create a mapping from class names to indices
        class_names = sorted(name for name in os.listdir(self.root_dir) if os.path.isdir(os.path.join(self.root_dir, name)))
        return {class_name: idx for idx, class_name in enumerate(class_names)}

    def _get_labels(self):
        labels = []
        for path in self.image_paths:
            label_name = os.path.basename(os.path.dirname(path))
            if label_name in self.class_names_to_idx:
                label = self.class_names_to_idx[label_name]
            else:
                raise ValueError(f"Label '{label_name}' not found in class_names_to_idx")
            labels.append(label)
        return labels

    def __getitem__(self, index):
        path = self.image_paths[index]
        image = Image.open(path).convert('RGB')
        label = self.labels[index]

        if self.transform:
            image = self.transform(image)
        if self.target_transform:
            label = self.target_transform(label)
        
        return image, label

    def __len__(self):
        return len(self.image_paths)


######

def smooth_loss(loss_history, smooth_window, variation_threshold):

    should_break = False
    
    # If enough losses have been collected, compute smoothed loss
    if len(loss_history) >= smooth_window:
        # Compute the smoothed loss (moving average)
        smooth_loss = sum(loss_history[-smooth_window:]) / smooth_window
        
        # Compute the variation (percentage change)
        if len(loss_history) >= smooth_window + 1:
            previous_smooth_loss = sum(loss_history[-(smooth_window+1):-1]) / smooth_window
            # Percentage change in loss
            variation = abs(smooth_loss - previous_smooth_loss) / previous_smooth_loss
            
            # Check if the variation is below the threshold
            if variation < variation_threshold:
                print(f'Variation on {smooth_window}: {variation} (thresh={variation_threshold}) (old={previous_smooth_loss}, new={smooth_loss})')
                should_break = True
         
    return should_break


# Function to check for rows in B that are not in A (numeric part)
# the current implementation of cat_new_rows becomes increasingly inefficient as A_numeric and A_bool grow.
# The primary issue stems from the fact that each call to cat_new_rows involves comparing every new 
# row against all existing rows in A_numeric and A_bool, resulting in a time complexity of O(n) 
# per iteration. As n grows, this quickly becomes a bottleneck.
# At the end 
# indicesAPN: Shape (N, 2) with index pairs.
# bools_APN: Shape (N, 1) with booleans.
def cat_new_rows(A_numeric, A_bool, B_numeric, B_bool):
    # Exclude rows in B_numeric that contain -1
    valid_rows_mask = (B_numeric != -1).all(dim=1)  # True for rows without -1   
    B_numeric_valid = B_numeric[valid_rows_mask]
    B_bool_valid = B_bool[valid_rows_mask]
    
    # Check if B_numeric_valid is empty
    if B_numeric_valid.size(0) == 0:
        return A_numeric, A_bool  # No new rows to add, return A as is
    
    # Check if A_numeric is empty
    if A_numeric.size(0) == 0:
        return B_numeric_valid, B_bool_valid
    
    # Compare the numeric parts and boolean parts
    matches_numeric = (A_numeric[:, None] == B_numeric_valid).all(-1).any(0)
    matches_bool = (A_bool[:, None] == B_bool_valid).all(-1).any(0)

    # Find the rows in B that are not in A
    matches_full = matches_numeric & matches_bool

    # Get the indices of the non-matching rows
    new_rows = ~matches_full

    # Extract the new rows from the valid B
    new_numeric = B_numeric_valid[new_rows]
    new_bool = B_bool_valid[new_rows]

    # Concatenate the new rows to A
    A_numeric_new = torch.cat((A_numeric, new_numeric), dim=0)
    A_bool_new = torch.cat((A_bool, new_bool), dim=0)

    return A_numeric_new, A_bool_new
# Get the new rows that are not in A
#A_numeric_new, A_bool_new = cat_new_rows(A_numeric, A_bool, B_numeric, B_bool)
#print("Updated A_numeric:\n", A_numeric_new)
#print("Updated A_bool:\n", A_bool_new)

# Switching from Tensors to Lists: Since we don't need tensors and will be saving/loading the data
# elsewhere, we'll use Python lists for accumulation, which are more efficient for dynamic operations like appending.
# Using a Hash-Based Set for Uniqueness: We'll convert each row into a unique, hashable identifier 
# (e.g., a tuple) and store these in a set. This allows for O(1) average-time complexity for membership checks, 
# ensuring that each row is only added once. 
# Ensuring 100% Uniqueness: By creating a unique identifier that includes all elements of a row, we ensure
# that each identifier is distinct. As long as the combination of elements in a row is unique, the identifier will be unique.
class RowManager:
    def __init__(self):
        # Initialize lists to accumulate new rows
        self.A_numeric_list = []
        self.A_bool_list = []
        # Initialize a set to store unique row identifiers
        self.row_set = set()

    def _row_to_key(self, numeric_row, bool_row):
        """
        Convert a row to a unique hashable key.
        Combines both numeric and boolean parts.
        """
        return tuple(numeric_row.tolist()) + tuple(bool_row.tolist())

    def add_new_rows(self, B_numeric, B_bool):
        """
        Add new rows from B to A if they don't already exist.
        """
        # Exclude rows in B_numeric that contain -1
        valid_mask = (B_numeric != -1).all(axis=1)  # Assuming B_numeric is a NumPy array
        B_numeric_valid = B_numeric[valid_mask]
        B_bool_valid = B_bool[valid_mask]
        
        # Iterate over B's valid rows and add unique ones
        new_numeric = []
        new_bool = []
        for num, bool_ in zip(B_numeric_valid, B_bool_valid):
            key = self._row_to_key(num, bool_)
            if key not in self.row_set:
                self.row_set.add(key)
                new_numeric.append(num)
                new_bool.append(bool_)
        
        # Append unique new rows to the accumulator lists
        self.A_numeric_list.extend(new_numeric)
        self.A_bool_list.extend(new_bool)
        
        return self.A_numeric_list, self.A_bool_list

    def get_final_lists(self):
        """
        Retrieve the final accumulated lists.
        """
        return self.A_numeric_list, self.A_bool_list
    

def cluster_accuracy(y_true, y_pred):
    """
    Compute cluster accuracy using Hungarian algorithm.

    Parameters:
        y_true (array-like): True labels.
        y_pred (array-like): Predicted labels.

    Returns:
        float: Accuracy score.
    """
    assert len(y_true) == len(y_pred)

    # Create the confusion matrix
    num_classes = int(max(max(y_true), max(y_pred)) + 1)
    confusion_matrix = np.zeros((num_classes, num_classes), dtype=np.int64)
    for i in range(len(y_true)):
        confusion_matrix[y_pred[i].astype(int), y_true[i].astype(int)] += 1

    # Use Hungarian algorithm to find optimal one-to-one mapping
    row_ind, col_ind = linear_sum_assignment(-confusion_matrix)

    # Compute accuracy based on the optimal mapping
    correct_matches = confusion_matrix[row_ind, col_ind].sum()
    total_matches = len(y_true)
    accuracy = correct_matches / total_matches

    return accuracy



# Early Stopping Class
class EarlyStopping:
    # Example usage
    # init
    # early_stopping = EarlyStopping(patience=5, min_delta=0.0025)
    # then in the training loop
    # ...
    # for data in dataloader
    #       ...
    #       early_stopping(-val_loss, model)        # call with "-" for loss, because we are checking is an perf indicator is < to previous to evaluate the patience
    #       or early_stopping(val_accuracy, model)  # if val_acc decrease "patience" times then stop
    #       if early_stopping.early_stop:    # check
    #           print("Early stopping")
    #           break
    
    def __init__(self, patience=5, min_delta=0.005):
        assert(min_delta > 0)
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.best_model_wts = None
        self.N = len(str(min_delta).split('.')[-1])

    def __call__(self, val_loss, model):
        #score = -val_loss
        score = val_loss
        if self.best_score is None:
            self.best_score = score
            self.best_model_wts = model.state_dict()
        elif round( np.abs(score - self.best_score), self.N) <= self.min_delta:
            self.counter += 1
            print(f'Early stopping -> crit={round( np.abs(score - self.best_score), self.N)} seuil {self.min_delta}, cpt={self.counter} (pat.={self.patience})')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.best_model_wts = model.state_dict()
            self.counter = 0
